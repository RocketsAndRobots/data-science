{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Flatten, Concatenate, Lambda, Dot, Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist data set and split it for 3 sets\n",
    "(X_train, y_train), (X_verif, y_verif) = mnist.load_data()\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_verif, y_verif, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073989f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the value range\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0739dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pairs of images that are the same class or a different one\n",
    "def generate_pairs(X, y):\n",
    "    number_classes = max(y) + 1\n",
    "    digit_inidices = [np.where(y == i)[0] for i in range(number_classes)]\n",
    "    \n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx1 in range(len(X)):\n",
    "        # example that matches\n",
    "        X1 = X[idx1]\n",
    "        y1 = y[idx1]\n",
    "        idx2 = random.choice(digit_inidices[y1])\n",
    "        X2 = X[idx2]\n",
    "        pairs.append([X1, X2])\n",
    "        labels.append(1)\n",
    "        \n",
    "        # example that does not match\n",
    "        y2 = random.randint(0, number_classes - 1)\n",
    "        while y1 == y2:\n",
    "            y2 = random.randint(0, number_classes - 1)\n",
    "            \n",
    "        idx2 = random.choice(digit_inidices[y2])\n",
    "        X2 = X[idx2]\n",
    "        pairs.append([X1, X2])\n",
    "        labels.append(0)\n",
    "        \n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c20827",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train, labels_train = generate_pairs(X_train, y_train)\n",
    "pairs_valid, labels_valid = generate_pairs(X_test, y_test)\n",
    "pairs_test, labels_test = generate_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show three random examples with their labels\n",
    "samples = random.sample(range(0, pairs_train.shape[0]), 3)\n",
    "\n",
    "fig, axar = plt.subplots(3, 2)\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "    axar[idx, 0].imshow(pairs_train[sample, 0])\n",
    "    axar[idx, 0].axis(False)\n",
    "    axar[idx, 1].imshow(pairs_train[sample, 1])\n",
    "    axar[idx, 1].axis(False)\n",
    "    print(\"Same:\", bool(labels_train[samples[idx]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc6a47",
   "metadata": {},
   "source": [
    "## Convolution network model without shared weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1464697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two networks each with their own weights. \n",
    "# The architecture is inspired by LeNet-5 by LeCun, Bottou, Bengio, and Haffner\n",
    "siam_net_1 = keras.Sequential(name='siamese-part1')\n",
    "siam_net_1.add(keras.layers.Input(shape=(28, 28, 1)))\n",
    "siam_net_1.add(keras.layers.Conv2D(input_shape=(28, 28, 1), filters= 6, kernel_size = (5, 5), \n",
    "                                    padding= 'same', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_1.add(keras.layers.Conv2D(filters= 16, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_1.add(keras.layers.Conv2D(filters= 120, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_1.add(keras.layers.Flatten())\n",
    "\n",
    "siam_net_2 = keras.Sequential(name='siamese-part2')\n",
    "siam_net_2.add(keras.layers.Input(shape=(28, 28, 1)))\n",
    "siam_net_2.add(keras.layers.Conv2D(input_shape=(28, 28, 1), filters= 6, kernel_size = (5, 5), \n",
    "                                    padding= 'same', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_2.add(keras.layers.Conv2D(filters= 16, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_2.add(keras.layers.Conv2D(filters= 120, kernel_size = (5, 5), \n",
    "                                padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_2.add(keras.layers.Flatten())\n",
    "\n",
    "# The output of the two siamese networks is flattened, concatenated, and then passed to a logistic layer\n",
    "merge_layer = keras.layers.Concatenate()([siam_net_1.output, siam_net_2.output])\n",
    "output_layer = keras.layers.Dense(units=1, activation='sigmoid')(merge_layer)\n",
    "mod_seperate_weights = keras.Model(name=\"split_concatenated\",inputs=[siam_net_1.input, siam_net_2.input], \n",
    "                             outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seperate_weights.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c71566",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mod_seperate_weights, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seperate_weights.fit(x=[pairs_train[:,0].reshape(-1 ,28 , 28, 1), pairs_train[:,1].reshape(-1 ,28 , 28, 1)], \n",
    "                        y=labels_train.reshape(-1,1), batch_size=16, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57255895",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seperate_weights.evaluate(x=[pairs_valid[:,0].reshape(-1, 28, 28, 1), pairs_valid[:,1].reshape(-1, 28, 28, 1)], \n",
    "                              y=labels_valid.reshape(-1, 1), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff1c77",
   "metadata": {},
   "source": [
    "## Introducing the euclidean distance / L2-Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332896c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to calculate the difference between two outputs\n",
    "def eukledian_distance(input_vector):\n",
    "    y_1, y_2 = input_vector\n",
    "    summed_square = tf.math.reduce_sum(tf.square(y_1 - y_2), axis=1 ,keepdims=True)\n",
    "    return tf.sqrt(tf.math.maximum(summed_square, keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "siam_net_1 = keras.Sequential(name='siamese-part1')\n",
    "siam_net_1.add(keras.layers.Input(shape=(28, 28, 1)))\n",
    "siam_net_1.add(keras.layers.Conv2D(input_shape=(28, 28, 1), filters= 6, kernel_size = (5, 5), \n",
    "                                    padding= 'same', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_1.add(keras.layers.Conv2D(filters= 16, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_1.add(keras.layers.Conv2D(filters= 120, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "\n",
    "siam_net_2 = keras.Sequential(name='siamese-part2')\n",
    "siam_net_2.add(keras.layers.Input(shape=(28, 28, 1)))\n",
    "siam_net_2.add(keras.layers.Conv2D(input_shape=(28, 28, 1), filters= 6, kernel_size = (5, 5), \n",
    "                                    padding= 'same', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_2.add(keras.layers.Conv2D(filters= 16, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "siam_net_2.add(keras.layers.Conv2D(filters= 120, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\"))\n",
    "\n",
    "# The output of the two siamese networks is flattened, euclidean distance applied, \n",
    "# and then passed to a logistic layer\n",
    "merge_layer = keras.layers.Lambda(eukledian_distance)([siam_net_1.layers[2].output, siam_net_2.layers[2].output])\n",
    "flatten_layer = keras.layers.Flatten()(merge_layer)\n",
    "output_layer = keras.layers.Dense(units=1, activation='sigmoid')(flatten_layer)\n",
    "mod_seperate_weights_l2 = keras.Model(name=\"split_l2_norm\",inputs=[siam_net_1.input, siam_net_2.input], \n",
    "                             outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seperate_weights_l2.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e202033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mod_seperate_weights_l2, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e2ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seperate_weights_l2.fit(x=[pairs_train[:,0].reshape(-1 ,28 , 28, 1), pairs_train[:,1].reshape(-1 ,28 , 28, 1)], \n",
    "                         y=labels_train.reshape(-1,1), batch_size=16, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seperate_weights_l2.evaluate(x=[pairs_valid[:,0].reshape(-1, 28, 28, 1), pairs_valid[:,1].reshape(-1, 28, 28, 1)], \n",
    "                                  y=labels_valid.reshape(-1, 1), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb536f",
   "metadata": {},
   "source": [
    "## Further improve by introducing shared weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da91c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=(28, 28, 1))\n",
    "conv2_layer_1 = keras.layers.Conv2D(input_shape=(28, 28, 1), filters= 6, kernel_size = (5, 5), \n",
    "                                    padding= 'same', activation='relu', data_format=\"channels_last\")(input_layer)\n",
    "pool_layer_1 = keras.layers.MaxPool2D()(conv2_layer_1)\n",
    "conv2_layer_2 = keras.layers.Conv2D(filters= 16, kernel_size = (5, 5), \n",
    "                                    padding= 'valid', activation='relu', data_format=\"channels_last\")(pool_layer_1)\n",
    "pool_layer_2 = keras.layers.MaxPool2D()(conv2_layer_2)\n",
    "nn_arch = keras.layers.Conv2D(filters= 120, kernel_size = (5, 5), \n",
    "                                padding= 'valid', activation='relu', data_format=\"channels_last\")(pool_layer_2)\n",
    "\n",
    "mod_shared_weights = keras.Model(input_layer, nn_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46287a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = keras.layers.Input(shape=(28, 28, 1))\n",
    "input_2 = keras.layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "siam_part_1 = mod_shared_weights(input_1)\n",
    "siam_part_2 = mod_shared_weights(input_2)\n",
    "\n",
    "merge_layer = keras.layers.Lambda(eukledian_distance)([siam_part_1, siam_part_2])\n",
    "flatten_layer = keras.layers.Flatten()(merge_layer)\n",
    "output_layer = keras.layers.Dense(units=1, activation='sigmoid')(flatten_layer)\n",
    "mod_siam_network = keras.Model(name=\"siamese-network\", inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_siam_network.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6594d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mod_siam_network, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_siam_network.fit(x=[pairs_train[:,0].reshape(-1 ,28 , 28, 1), pairs_train[:,1].reshape(-1 ,28 , 28, 1)], \n",
    "                        y=labels_train.reshape(-1,1), batch_size=16, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54073f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_siam_network.evaluate(x=[pairs_valid[:,0].reshape(-1, 28, 28, 1), pairs_valid[:,1].reshape(-1, 28, 28, 1)], \n",
    "                            y=labels_valid.reshape(-1, 1), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bda340",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_siam_network.evaluate(x=[pairs_test[:,0].reshape(-1, 28, 28, 1), pairs_test[:,1].reshape(-1, 28, 28, 1)], \n",
    "                            y=labels_test.reshape(-1, 1), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict a random sample and show it\n",
    "random_sample = random.randint(0, pairs_test.shape[0])\n",
    "prediction = mod_siam_network.predict(x=[pairs_train[random_sample,0].reshape(-1, 28, 28, 1), \n",
    "                                             pairs_train[random_sample,1].reshape(-1, 28, 28, 1)])\n",
    "\n",
    "if prediction > 0.5:\n",
    "    print(\"Predicted label: 1\")\n",
    "else:\n",
    "    print(\"Predicted label: 0\")\n",
    "    \n",
    "fig, axar = plt.subplots(1, 2)\n",
    "for j in range(0, 2):\n",
    "    axar[j].axis(False)\n",
    "    \n",
    "axar[0].imshow(pairs_train[random_sample, 0])\n",
    "axar[1].imshow(pairs_train[random_sample, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c1160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
